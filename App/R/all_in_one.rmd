---
params:
  data_path: ""
  target_var: ""
  chosen_vars: ""
  output_path: ""
  
---

```{r include=FALSE}
write(append = F,x = "R Loaded",file = "log.txt")
write(append = T,sep = "\n" ,x = "Loading Python",file = "log.txt")
library("reticulate")
use_python("path/to/your/python/bin", required = T)
data_path <- params$data_path
target_var <- params$target_var
chosen_vars <- params$chosen_vars
output_path <- params$output_path

```
```{python include=FALSE}
with open('log.txt', 'a') as f:
    f.write('Loading python libraries...')
# Required libraries
import pandas as pd
import numpy as np
import os
import datetime
from sklearn.compose import *
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import *
from sklearn.impute import *
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

from sklearn.model_selection import RandomizedSearchCV

# Data import
df = pd.read_csv(r['data_path'])

# Features and target variables
target_var = r['target_var']
X = df.drop(target_var,axis=1)
if r['chosen_vars'] != "":
  X = X.loc[:,r['chosen_vars']]
y = df[target_var]

# Splitting features into categories and numerics

selector1 = make_column_selector(dtype_exclude=object)
selector2 = make_column_selector(dtype_exclude='number')
numerics =  X[selector1].columns
categoricals =  X[selector2].columns

# Pipeline
numeric_transformer = Pipeline(
    steps=[("imputer", SimpleImputer()), ("scaler", StandardScaler())]
)

categorical_transformer = Pipeline(
    steps=[("encoder", OneHotEncoder() )]
)

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numerics),
        ("cat", categorical_transformer, categoricals),
    ]
)

# Append classifier to preprocessing pipeline.

# Full transformation and prediction pipeline.
pipe = Pipeline(
    steps=[("preprocessor", preprocessor), ("model", LogisticRegression())]
)

with open('log.txt', 'a') as f:
    f.write('pipeline created')

# grid of params
# scalers
stdScaler = StandardScaler()
minMaxScaler = MinMaxScaler()
scalers = [stdScaler,minMaxScaler]
# Encoders
ordinalEncoder = OrdinalEncoder(handle_unknown="use_encoded_value",unknown_value=999)
ohe = OneHotEncoder(handle_unknown="ignore")
encoders = [ohe,ordinalEncoder]


# common params 
imputers = [SimpleImputer(strategy="mean"),
            SimpleImputer(strategy="most_frequent"),
            KNNImputer(n_neighbors = 5),
            KNNImputer(n_neighbors = 10)]

common_params = {}
common_params["preprocessor__num__imputer"] = imputers
common_params["preprocessor__num__scaler"] = scalers
common_params["preprocessor__cat__encoder"] = encoders

# Models params

# models
knn = KNeighborsClassifier()
rf = RandomForestClassifier()
logreg = LogisticRegression()
mlp = MLPClassifier(max_iter=200,n_iter_no_change=10)
svc = SVC()



svc_params = {}
svc_params["model"] = [svc]
svc_params["model__C"] = range(1,50,10)
# svc_params["model__kernel"] = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']
svc_params["model__kernel"] = ['rbf']
svc_params['model__gamma'] = ['scale', 'auto']
svc_params['model__coef0'] = [1]
svc_params['model__shrinking'] = [True,False]
svc_params['model__probability'] = [True,False]


knn_params = {}
knn_params["model"] = [knn]
knn_params["model__n_neighbors"] = [*range(1,50,3)]
knn_params["model__weights"] = ['uniform', 'distance']
knn_params["model__algorithm"] = ['ball_tree', 'kd_tree']
knn_params["model__leaf_size"] = [*range(1,350,5)]

rf_params = {}
rf_params["model"] = [rf]
rf_params["model__n_estimators"] = [*range(1,200,5)]
rf_params["model__criterion"] = ["gini", "entropy"]
rf_params["model__max_features"] = ["sqrt", "log2"]
rf_params["model__bootstrap"] = [True,False]

logreg_params = {}
logreg_params["model"] = [logreg]
logreg_params["model__C"] = [*range(1,50,5)]
logreg_params["model__multi_class"] = ['ovr', 'multinomial']
# logreg_params["model__solver"] = ['newton-cg', 'lbfgs', 'sag', 'saga']
logreg_params["model__solver"] = ['saga']

mlp_params = {}
mlp_params["model"] = [mlp]
mlp_params["model__hidden_layer_sizes"] = [(100,),(150,),(200,),(250,),(100,100),(560,50),(640,20),(80,80),(200,5),(20,),(100,150),(560,4)]
mlp_params["model__activation"] = ['identity', 'logistic', 'tanh', 'relu']
mlp_params["model__solver"] = ['lbfgs', 'sgd', 'adam']
mlp_params["model__learning_rate"] = ['constant', 'invscaling', 'adaptive']

models_params = [knn_params,mlp_params,rf_params,svc_params,logreg_params]

with open('log.txt', 'a') as f:
    f.write('grid parameters created')

# grid searching 

mydir = os.path.join("../analysis_history",datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))
os.makedirs(mydir)
os.makedirs(mydir+"/data")
os.makedirs(mydir+"/models_params")
open(mydir + "/models_params/model_params.txt", "x")
os.makedirs(mydir+"/models")
os.makedirs(mydir+"/images")
os.makedirs(mydir+"/images/knn")
os.makedirs(mydir+"/images/rf")
os.makedirs(mydir+"/images/mlp")
os.makedirs(mydir+"/images/lr")
os.makedirs(mydir+"/images/svc")
index = 0
path = 'log.txt'
best_models = {}

for model_param in models_params:
    with open('log.txt', 'a') as f:
        f.write('Grid search with' + str(model_param["model"]))
    current_param = model_param.copy()
    current_param.update(common_params)
    grid = RandomizedSearchCV(pipe,current_param,cv=5,n_jobs=-1,n_iter = 50)
    fitted = grid.fit(X,y)
    with open('log.txt', 'a') as f:
        f.write('Grid fitted')
    result = pd.DataFrame(grid.cv_results_)
    model_name = str(model_param['model'])
    model_name = model_name[1:model_name.find("(")]
    filename = mydir+ "/data/" + model_name + ".csv"
    index = index + 1
    result.to_csv(filename)  
    with open('log.txt', 'a') as f:
      f.write('Grid search finished with best score of : ' + str(fitted.best_score_))
    best_models[index] = {"score" : grid.best_score_ , "params" : grid.best_params_}
f.close()

```

```{r include=FALSE}
# Data cleaning
write(append = T,sep = "\n" ,x = "Cleaning data...",file = "log.txt")
data_files = list.files(path= paste0(py$mydir,"/data/"))
data_names = NA
i=1
for(file in data_files){
  eval(parse(text = paste0(gsub(".csv","",file),"<-read.csv('",py$mydir,"/data/",file,"')") ))
  data_names[i] = gsub(".csv","",file)
  i = i +1
}

all_data = data.frame(mean_test_score=NA, std_test_score= NA , param_model = NA) 

for(data_name in data_names){

  data <- get(data_name)  
  
for(i in 1:nrow(data)){
  old = data$param_preprocessor__cat__encoder[i]
  to = gregexpr("\\(",old)[[1]][1]
  data$param_preprocessor__cat__encoder[i] = substr(old,0,to-1)
  
  
  old = data$param_preprocessor__num__imputer[i]
  to = gregexpr("\\(",old)[[1]][1]
  data$param_preprocessor__num__imputer[i] = substr(old,0,to-1)
  
  old = data$param_preprocessor__num__scaler[i]
  to = gregexpr("\\(",old)[[1]][1]
  data$param_preprocessor__num__scaler[i] = substr(old,0,to-1)
  
  old = data$param_model[i]
  to = gregexpr("\\(",old)[[1]][1]
  data$param_model[i] = substr(old,0,to-1)
  
}
  eval(parse(text = paste(data_name,"<- data")))
  write.csv(data,file = paste0(py$mydir,"/data/",data_name,".csv"))
  all_data = rbind(all_data,data[,c("mean_test_score","std_test_score","param_model")])
}

write.csv(all_data[-1,],file = paste0(py$mydir,"/data/all_data",".csv"))
```

```{r include=FALSE}
# Plotting
write(append = T,sep = "\n" ,x = "Preparing some great graphics...",file = "log.txt")

LogisticRegression_params = list(name = "lr",data = get("LogisticRegression"), 
                                 list_params=c("param_model__C",
                                               "param_preprocessor__num__scaler",
                                               "param_model__multi_class",
                                               "param_model__solver",
                                               "param_preprocessor__cat__encoder",
                                               "param_preprocessor__num__imputer"))



KNeighborsClassifier_params = list(name = "knn", data = get("KNeighborsClassifier"), 
                                   list_params=  c("param_model__algorithm",
                                                   "param_model__leaf_size",
                                                   "param_model__n_neighbors",       
                                                   "param_model__weights",
                                                   "param_preprocessor__cat__encoder",
                                                   "param_preprocessor__num__imputer",
                                                   "param_preprocessor__num__scaler" ))

RandomForest_params = list(name = "rf",data = get("RandomForestClassifier"), 
                           list_params= c("param_model__bootstrap",
                                          "param_preprocessor__num__scaler",
                                          "param_model__criterion",
                                          "param_model__max_features",
                                          "param_model__n_estimators",
                                          "param_preprocessor__cat__encoder",
                                          "param_preprocessor__num__imputer"))

SVC_params = list(name="svc",data = get("SVC"), list_params= c("param_model__C",
                                                                   "param_preprocessor__num__scaler",
                                                                   "param_model__kernel",
                                                                   "param_model__gamma",
                                                                   "param_model__coef0",
                                                                   "param_model__shrinking", 
                                                                   "param_model__probability", 
                                                                   "param_preprocessor__cat__encoder",
                                                                   "param_preprocessor__num__imputer" ))

MLPClassifier_params = list(name="mlp",data = get("MLPClassifier"), list_params= c("param_model__activation",
                                                                   "param_preprocessor__num__scaler",
                                                                   "param_model__hidden_layer_sizes",
                                                                   "param_model__learning_rate",
                                                                   "param_model__solver",           
                                                                   "param_preprocessor__cat__encoder",
                                                                   "param_preprocessor__num__imputer" ))


makePlot <- function(data,x="mean_test_score",y="std_test_score",color){
  a= gregexpr("\\(",data$param_model[1])[[1]][1]
  model_name = substr(data$param_model[1],10, a - 1)
  x_name = gsub("_"," ",x)
  y_name = gsub("_"," ",y)
  color_name = gsub("param_model__","",color)
  color_name = gsub("param_preprocessor__cat__","",color_name)
  color_name = gsub("param_preprocessor__num__","",color_name)
  color_name = gsub("_"," ",color_name)
  require(ggplot2)
  require(see)
  p <- ggplot(data,aes(data[,x],data[,y],color = data[,color]))+
    geom_point(size=6,alpha = 0.7) + theme_lucid(base_size = 40) +
    labs(title = paste("Grid searching results : ",model_name),
         x = x_name,
         y= y_name,
         color = color_name)
  list(plot = p , name = color)
}

all_params = list(KNeighborsClassifier_params,
               LogisticRegression_params,
               RandomForest_params,MLPClassifier_params,SVC_params)

i = 0
for(p in all_params){
  for(param in p$list_params){
    print(param)
    res = makePlot(as.data.frame(p$data),color=param)
    plot = res$plot
    if(i == 0) {
      write(append = T,sep = "\n" ,x = "Saving images...",file = "log.txt")
      i= i + 1
    }
    ggsave(units = "px",width = 2400,height = 1700,
           path =  paste0(py$mydir,"/images/",p$name,"/"),filename=paste0(param,".png"))
  }
}

makePlot(all_data,color = "param_model")

ggsave(units = "px",width = 2400,height = 1700,
       path =  paste0(py$mydir,"/images/"),filename="allModels.png")

con = "../last_instance.txt"
if(file.exists(con)){
  file.remove(con)
}
file.create(con)
writeLines(con = con,text = py$mydir)
write(append = T,sep = "\n" ,x = "Process complete, you can go go to IDE to visualize the results",file = "log.txt")
```
