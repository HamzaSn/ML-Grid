---
params:
    data_path: ""
    target_var: ""
    chosen_vars: ""
    session_name: ""
---

```{r include=FALSE}
write(append = F,x = "R Loaded",file = "log.txt")
write(append = T,sep = "\n" ,x = "Loading Python",file = "log.txt")
library("reticulate")
use_python("path/to your/bin/python", required = T)
data_path <- params$data_path
target_var <- params$target_var
chosen_vars <- params$chosen_vars
session_name <- params$session_name
```


```{python include=FALSE}
with open('log.txt', 'a') as f:
    f.write('Loading python libraries...')
# Required libraries
import pandas as pd
import numpy as np
import os
import datetime
from sklearn.compose import *
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import *
from sklearn.impute import *
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.experimental import enable_halving_search_cv
from sklearn.model_selection import HalvingRandomSearchCV
from sklearn.model_selection import RandomizedSearchCV

# Data import
df = pd.read_csv(r['data_path'])

# Features and target variables
target_var = r['target_var']
X = df.drop(target_var,axis=1)
if r['chosen_vars'] != "":
    X = X.loc[:,r['chosen_vars']]
y = df[target_var]

# Splitting features into categories and numerics

selector1 = make_column_selector(dtype_exclude=object)
selector2 = make_column_selector(dtype_exclude='number')
numerics =  X[selector1].columns
categoricals =  X[selector2].columns

# Pipeline
numeric_transformer = Pipeline(
    steps=[("imputer", SimpleImputer()), ("scaler", StandardScaler())]
)

categorical_transformer = Pipeline(
    steps=[("encoder", OneHotEncoder() )]
)

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numerics),
        ("cat", categorical_transformer, categoricals),
    ]
)

# Append classifier to preprocessing pipeline.

# Full transformation and prediction pipeline.
pipe = Pipeline(
    steps=[("preprocessor", preprocessor), ("model", LogisticRegression())]
)

with open('log.txt', 'a') as f:
    f.write('pipeline created')

# grid of params
# scalers
stdScaler = StandardScaler()
minMaxScaler = MinMaxScaler()
scalers = [stdScaler,minMaxScaler]
# Encoders
ordinalEncoder = OrdinalEncoder(handle_unknown="use_encoded_value",unknown_value=999)
ohe = OneHotEncoder(handle_unknown="ignore")
encoders = [ohe,ordinalEncoder]


# common params
imputers = [SimpleImputer(strategy="mean"),
            SimpleImputer(strategy="most_frequent"),
            KNNImputer(n_neighbors = 5),
            KNNImputer(n_neighbors = 10)]

common_params = {}
common_params["preprocessor__num__imputer"] = imputers
common_params["preprocessor__num__scaler"] = scalers
common_params["preprocessor__cat__encoder"] = encoders

# Models params

# models
knn = KNeighborsClassifier()
rf = RandomForestClassifier()
logreg = LogisticRegression()
mlp = MLPClassifier(max_iter=100,n_iter_no_change=10)
svc = SVC()

svc_params = {}
svc_params["model"] = [svc]
svc_params["model__C"] = range(1,50,10)
svc_params["model__kernel"] = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']
svc_params['model__gamma'] = ['scale', 'auto']
svc_params['model__coef0'] = range(1,10,1)
svc_params['model__shrinking'] = [True,False]
svc_params['model__probability'] = [True,False]


knn_params = {}
knn_params["model"] = [knn]
knn_params["model__n_neighbors"] = [*range(1,50,3)]
knn_params["model__weights"] = ['uniform', 'distance']
knn_params["model__algorithm"] = ['ball_tree', 'kd_tree']
knn_params["model__leaf_size"] = [*range(1,350,5)]

rf_params = {}
rf_params["model"] = [rf]
rf_params["model__n_estimators"] = [*range(1,200,5)]
rf_params["model__criterion"] = ["gini", "entropy"]
rf_params["model__max_features"] = ["sqrt", "log2"]
rf_params["model__bootstrap"] = [True,False]

logreg_params = {}
logreg_params["model"] = [logreg]
logreg_params["model__C"] = [*range(1,50,5)]
logreg_params["model__multi_class"] = ['ovr', 'multinomial']
logreg_params["model__solver"] = ['newton-cg', 'lbfgs', 'sag', 'saga']


mlp_params = {}
mlp_params["model"] = [mlp]
mlp_params["model__hidden_layer_sizes"] = [(100,),(150,),(200,),(250,),(100,100),(560,50),(640,20),(80,80),(200,5),(20,),(100,150),(560,4)]
mlp_params["model__activation"] = ['identity', 'logistic', 'tanh', 'relu']
mlp_params["model__solver"] = ['lbfgs', 'sgd', 'adam']
mlp_params["model__learning_rate"] = ['constant', 'invscaling', 'adaptive']

models_params = [knn_params,mlp_params,rf_params,svc_params,logreg_params]

with open('log.txt', 'a') as f:
    f.write('grid parameters created')

# grid searching
session_name = r['session_name']
if session_name == "":
  session_name = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')

mydir = os.path.join("../analysis_history",session_name)
os.makedirs(mydir)
os.makedirs(mydir+"/data")
os.makedirs(mydir+"/models_params")
os.makedirs(mydir+"/models")
os.makedirs(mydir+"/images")
os.makedirs(mydir+"/images/knn")
os.makedirs(mydir+"/images/rf")
os.makedirs(mydir+"/images/mlp")
os.makedirs(mydir+"/images/lr")
os.makedirs(mydir+"/images/svc")
index = 0

path = 'log.txt'
best_models = {}
for model_param in models_params:
    with open('log.txt', 'a') as f:
        f.write('Grid search with' + str(model_param["model"]))
    current_param = model_param.copy()
    current_param.update(common_params)
    grid = RandomizedSearchCV(pipe,current_param,cv=5,n_iter = 50,n_jobs=-1)
    fitted = grid.fit(X,y)
    with open('log.txt', 'a') as f:
        f.write('Grid fitted')
    result = pd.DataFrame(grid.cv_results_)
    model_name = str(model_param['model'])
    model_name = model_name[1:model_name.find("(")]
    filename = mydir+ "/data/" + model_name + ".csv"
    result.to_csv(filename)
    with open('log.txt', 'a') as f:
        f.write('Grid search finished with best score of : ' + str(fitted.best_score_))
    best_models[index] = {"score" : grid.best_score_ , "params" : grid.best_params_}
    index = index + 1
f.close()
```



```{r include=FALSE}
old = py$best_models[['0']][['params']][['model']]
to = gregexpr("\\(",old)[[1]][1]
model_name =  substr(old,0,to-1)

score =  py$best_models[['0']][['score']]

old = py$best_models[['0']][['params']][['preprocessor__num__imputer']]
to = gregexpr("\\(",old)[[1]][1]
imputer =  substr(old,0,to-1)

old = py$best_models[['0']][['params']][['preprocessor__cat__encoder']]
to = gregexpr("\\(",old)[[1]][1]
encoder =  substr(old,0,to-1)

old = py$best_models[['0']][['params']][['preprocessor__num__scaler']]
to = gregexpr("\\(",old)[[1]][1]
scaler =  substr(old,0,to-1)

n_neighbors = py$best_models[['0']][['params']][['model__n_neighbors']]

leaf_size = py$best_models[['0']][['params']][['model__leaf_size']]

weights = py$best_models[['0']][['params']][['model__weights']]

algorithm = py$best_models[['0']][['params']][['model__algorithm']]

best_param1 = paste(
  "Model name : " , model_name, "\n",
  "Best Score : " , score,"\n",
  "Imputer used : ", imputer,"\n",
  "Numeric scaler used : ", scaler,"\n",
  "Categories encoder used : ", encoder,"\n",
  "Number of neighbors (n_neighbors) : " , n_neighbors,"\n",
  "Leaf size (leaf_size) : ", leaf_size,"\n",
  "Weights (weights) : " , weights,"\n",
  "Algorithm (algorithm) : ", algorithm,"\n"
)

write(append = F,sep = "\n" ,x = best_param1,
      file = paste0(py$mydir,"/models_params/knn_best_params.txt"))

old = py$best_models[['1']][['params']][['model']]
to = gregexpr("\\(",old)[[1]][1]
model_name =  substr(old,0,to-1)

score =  py$best_models[['1']][['score']]

old = py$best_models[['1']][['params']][['preprocessor__num__imputer']]
to = gregexpr("\\(",old)[[1]][1]
imputer =  substr(old,0,to-1)

old = py$best_models[['1']][['params']][['preprocessor__cat__encoder']]
to = gregexpr("\\(",old)[[1]][1]
encoder =  substr(old,0,to-1)

old = py$best_models[['1']][['params']][['preprocessor__num__scaler']]
to = gregexpr("\\(",old)[[1]][1]
scaler =  substr(old,0,to-1)

hidden_layer_sizes = unlist(py$best_models[['1']][['params']][['model__hidden_layer_sizes']]) 
hidden_layer_sizes = paste0("(",hidden_layer_sizes[1],",",hidden_layer_sizes[2],")")

activation = py$best_models[['1']][['params']][['model__activation']]

solver = py$best_models[['1']][['params']][['model__solver']]

learning_rate = py$best_models[['1']][['params']][['model__learning_rate']]

best_param2 = paste(
  "Model name : " , model_name, "\n",
  "Best Score : " , score,"\n",
  "Imputer used : ", imputer,"\n",
  "Numeric scaler used : ", scaler,"\n",
  "Categories encoder used : ", encoder,"\n",
  "Hidden layer sizes (hidden_layer_sizes) : " , hidden_layer_sizes,"\n",
  "Activation (activation) : ", activation,"\n",
  "Solver (solver) : " , solver,"\n",
  "Learning rate (learning_rate) : ", learning_rate,"\n"
)

write(append = F,sep = "\n" ,x = best_param2,
      file = paste0(py$mydir,"/models_params/mlp_best_params.txt"))

old = py$best_models[['2']][['params']][['model']]
to = gregexpr("\\(",old)[[1]][1]
model_name =  substr(old,0,to-1)

score =  py$best_models[['2']][['score']]

old = py$best_models[['2']][['params']][['preprocessor__num__imputer']]
to = gregexpr("\\(",old)[[1]][1]
imputer =  substr(old,0,to-1)

old = py$best_models[['2']][['params']][['preprocessor__cat__encoder']]
to = gregexpr("\\(",old)[[1]][1]
encoder =  substr(old,0,to-1)

old = py$best_models[['2']][['params']][['preprocessor__num__scaler']]
to = gregexpr("\\(",old)[[1]][1]
scaler =  substr(old,0,to-1)

n_estimators = py$best_models[['2']][['params']][['model__n_estimators']]

criterion = py$best_models[['2']][['params']][['model__criterion']]

max_features = py$best_models[['2']][['params']][['model__max_features']]

bootstrap = py$best_models[['2']][['params']][['model__bootstrap']]

best_param3 = paste(
  "Model name : " , model_name, "\n",
  "Best Score : " , score,"\n",
  "Imputer used : ", imputer,"\n",
  "Numeric scaler used : ", scaler,"\n",
  "Categories encoder used : ", encoder,"\n",
  "Number of estimators (n_estimators) : " , n_estimators,"\n",
  "Criterion (criterion): ", criterion,"\n",
  "Max features (max_features) : " , max_features,"\n",
  "Bootstrap (bootstrap) : ", bootstrap,"\n"

)

write(append = F,sep = "\n" ,x = best_param3,
      file = paste0(py$mydir,"/models_params/rf_best_params.txt"))


old = py$best_models[['3']][['params']][['model']]
to = gregexpr("\\(",old)[[1]][1]
model_name =  substr(old,0,to-1)

score =  py$best_models[['3']][['score']]

old = py$best_models[['3']][['params']][['preprocessor__num__imputer']]
to = gregexpr("\\(",old)[[1]][1]
imputer =  substr(old,0,to-1)

old = py$best_models[['3']][['params']][['preprocessor__cat__encoder']]
to = gregexpr("\\(",old)[[1]][1]
encoder =  substr(old,0,to-1)

old = py$best_models[['3']][['params']][['preprocessor__num__scaler']]
to = gregexpr("\\(",old)[[1]][1]
scaler =  substr(old,0,to-1)

C = py$best_models[['3']][['params']][['model__C']]

kernel = py$best_models[['3']][['params']][['model__kernel']]

gamma = py$best_models[['3']][['params']][['model__gamma']]

coef0 = py$best_models[['3']][['params']][['model__coef0']]

shrinking = py$best_models[['3']][['params']][['model__shrinking']]

probability = py$best_models[['3']][['params']][['model__probability']]

best_param4 = paste(
  "Model name : " , model_name, "\n",
  "Best Score : " , score,"\n",
  "Imputer used : ", imputer,"\n",
  "Numeric scaler used : ", scaler,"\n",
  "Categories encoder used : ", encoder,"\n",
  "C parameter (C) : " , C,"\n",
  "Kernel (kernel): ", kernel,"\n",
  "Gamma (gamma) : " , gamma,"\n",
  "Coef0 (coef0) : ", coef0,"\n",
  "Shrinking (bootstrap) : ", shrinking,"\n",
  "Probablity (probablity) : ", probability,"\n"

)

write(append = F,sep = "\n" ,x = best_param4,
      file = paste0(py$mydir,"/models_params/svc_best_params.txt"))

old = py$best_models[['4']][['params']][['model']]
to = gregexpr("\\(",old)[[1]][1]
model_name =  substr(old,0,to-1)

score =  py$best_models[['4']][['score']]

old = py$best_models[['4']][['params']][['preprocessor__num__imputer']]
to = gregexpr("\\(",old)[[1]][1]
imputer =  substr(old,0,to-1)

old = py$best_models[['4']][['params']][['preprocessor__cat__encoder']]
to = gregexpr("\\(",old)[[1]][1]
encoder =  substr(old,0,to-1)

old = py$best_models[['4']][['params']][['preprocessor__num__scaler']]
to = gregexpr("\\(",old)[[1]][1]
scaler =  substr(old,0,to-1)

C = py$best_models[['4']][['params']][['model__C']]

solver = py$best_models[['4']][['params']][['model__solver']]

multi_class = py$best_models[['4']][['params']][['model__multi_class']]

best_param5 = paste(
  "Model name : " , model_name, "\n",
  "Best Score : " , score,"\n",
  "Imputer used : ", imputer,"\n",
  "Numeric scaler used : ", scaler,"\n",
  "Categories encoder used : ", encoder,"\n",
  "C parameter (C) : " , C,"\n",
  "Kernel (kernel): ", solver,"\n",
  "Gamma (gamma) : " , multi_class,"\n"
)

write(append = F,sep = "\n" ,x = best_param5,
      file = paste0(py$mydir,"/models_params/lr_best_params.txt"))

scores = NA
for(i in 0:4){
  scores[i+1] = as.numeric(py$best_models[[as.character(i)]][['score']])
}

index_max = which(scores==max(scores))[[1]]
name_of_msg = paste0("best_param",index_max)
write(append = F,sep = "\n" ,x = get(name_of_msg),
      file = paste0(py$mydir,"/models_params/all_best_params.txt"))

```


```{r include=FALSE}
# Data cleaning
write(append = T,sep = "\n" ,x = "Cleaning data...",file = "log.txt")
data_files = list.files(path= paste0(py$mydir,"/data/"))
data_names = NA
i=1
for(file in data_files){
  eval(parse(text = paste0(gsub(".csv","",file),"<-read.csv('",py$mydir,"/data/",file,"')") ))
  data_names[i] = gsub(".csv","",file)
  i = i +1
}

all_data = data.frame(mean_test_score=NA, std_test_score= NA , param_model = NA)

for(data_name in data_names){

  data <- get(data_name)

  for(i in 1:nrow(data)){
    old = data$param_preprocessor__cat__encoder[i]
    to = gregexpr("\\(",old)[[1]][1]
    data$param_preprocessor__cat__encoder[i] = substr(old,0,to-1)


    old = data$param_preprocessor__num__imputer[i]
    to = gregexpr("\\(",old)[[1]][1]
    data$param_preprocessor__num__imputer[i] = substr(old,0,to-1)

    old = data$param_preprocessor__num__scaler[i]
    to = gregexpr("\\(",old)[[1]][1]
    data$param_preprocessor__num__scaler[i] = substr(old,0,to-1)

    old = data$param_model[i]
    to = gregexpr("\\(",old)[[1]][1]
    data$param_model[i] = substr(old,0,to-1)

  }
  eval(parse(text = paste(data_name,"<- data")))
  write.csv(data,file = paste0(py$mydir,"/data/",data_name,".csv"))
  all_data = rbind(all_data,data[,c("mean_test_score","std_test_score","param_model")])
}

write.csv(all_data[-1,],file = paste0(py$mydir,"/data/all_data",".csv"))
```


```{r include=FALSE}
# Plotting
write(append = T,sep = "\n" ,x = "Preparing some great graphics...",file = "log.txt")

LogisticRegression_params = list(name = "lr",data = get("LogisticRegression"),
                                 list_params=c("param_model__C",
                                               "param_preprocessor__num__scaler",
                                               "param_model__multi_class",
                                               "param_model__solver",
                                               "param_preprocessor__cat__encoder",
                                               "param_preprocessor__num__imputer"))



KNeighborsClassifier_params = list(name = "knn", data = get("KNeighborsClassifier"),
                                   list_params=  c("param_model__algorithm",
                                                   "param_model__leaf_size",
                                                   "param_model__n_neighbors",
                                                   "param_model__weights",
                                                   "param_preprocessor__cat__encoder",
                                                   "param_preprocessor__num__imputer",
                                                   "param_preprocessor__num__scaler" ))

RandomForest_params = list(name = "rf",data = get("RandomForestClassifier"),
                           list_params= c("param_model__bootstrap",
                                          "param_preprocessor__num__scaler",
                                          "param_model__criterion",
                                          "param_model__max_features",
                                          "param_model__n_estimators",
                                          "param_preprocessor__cat__encoder",
                                          "param_preprocessor__num__imputer"))

SVC_params = list(name="svc",data = get("SVC"), list_params= c("param_model__C",
                                                               "param_preprocessor__num__scaler",
                                                               "param_model__kernel",
                                                               "param_model__gamma",
                                                               "param_model__coef0",
                                                               "param_model__shrinking",
                                                               "param_model__probability",
                                                               "param_preprocessor__cat__encoder",
                                                               "param_preprocessor__num__imputer" ))

MLPClassifier_params = list(name="mlp",data = get("MLPClassifier"), list_params= c("param_model__activation",
                                                                                   "param_preprocessor__num__scaler",
                                                                                   "param_model__hidden_layer_sizes",
                                                                                   "param_model__learning_rate",
                                                                                   "param_model__solver",
                                                                                   "param_preprocessor__cat__encoder",
                                                                                   "param_preprocessor__num__imputer" ))

makePlot <- function(data,x="mean_test_score",y="std_test_score",color,plot_name=""){
  if(plot_name != ""){
    model_name = plot_name
  } else {
    model_name = data$param_model[1]
  }
  
  x_name = gsub("_"," ",x)
  y_name = gsub("_"," ",y)
  color_name = gsub("param_model__","",color)
  color_name = gsub("param_preprocessor__cat__","",color_name)
  color_name = gsub("param_preprocessor__num__","",color_name)
  color_name = gsub("_"," ",color_name)
  require(ggplot2)
  require(see)
  p <- ggplot(data,aes(data[,x],data[,y],color = data[,color]))+
    geom_point(size=6,alpha = 0.7) + theme_lucid(base_size = 40) +
    labs(title = paste("Grid searching results : ",model_name),
         x = x_name,
         y= y_name,
         color = color_name)
  list(plot = p , name = color)
}


all_params = list(KNeighborsClassifier_params,
                  LogisticRegression_params,
                  RandomForest_params,MLPClassifier_params,SVC_params)

i = 0
for(p in all_params){
  for(param in p$list_params){
    print(param)
    res = makePlot(as.data.frame(p$data),color=param)
    plot = res$plot
    if(i == 0) {
      write(append = T,sep = "\n" ,x = "Saving images...",file = "log.txt")
      i= i + 1
    }
    ggsave(units = "px",width = 2400,height = 1700,
           path =  paste0(py$mydir,"/images/",p$name,"/"),filename=paste0(param,".png"))
  }
}



all_data= na.omit(all_data)
makePlot(all_data,color = "param_model",plot_name = "All models")

ggsave(units = "px",width = 2400,height = 1700,
       path =  paste0(py$mydir,"/images/"),filename="allModels.png")

con = "../last_instance.txt"
if(file.exists(con)){
  file.remove(con)
}
file.create(con)
writeLines(con = con,text = substr(py$mydir,2,nchar(py$mydir)))
write(append = T,sep = "\n" ,x = "Process complete, you can go go to IDE to visualize the results",file = "log.txt")
```




